{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/zyc62/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import time\n",
    "notebookstart= time.time()\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# Gradient Boosting\n",
    "#import lightgbm as lgb\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "#HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('demo10100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Load Stage\n",
      "RangeIndex(start=0, stop=10100, step=1)\n",
      "[nltk_data] Downloading package stopwords to /home/zyc62/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Load Stage\")\n",
    "df = pd.read_csv('demo10100.csv',parse_dates = [\"activation_date\"])\n",
    "df_index = df.index\n",
    "print(df_index)\n",
    "\n",
    "#testing = pd.read_csv('test.csv',parse_dates = [\"activation_date\"])\n",
    "#testdex = testing.index\n",
    "#test_item = testing['item_id']\n",
    "\n",
    "y = df['deal_probability'].copy()\n",
    "df.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "\n",
    "#print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
    "#print('Test shape: {} Rows, {} Columns'.format(*testing.shape))\n",
    "\n",
    "df[\"price\"] = np.log(df[\"price\"]+0.001)               # filling in NaN's\n",
    "df[\"price\"].fillna(-999,inplace=True)\n",
    "df[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "df['param_1'].fillna('fill',inplace=True)\n",
    "df['param_2'].fillna('fill',inplace=True)\n",
    "df['param_3'].fillna('fill',inplace=True)\n",
    "\n",
    "df[\"Weekday\"] = df['activation_date'].dt.weekday\n",
    "df[\"Weekd of Year\"] = df['activation_date'].dt.week\n",
    "df[\"Day of Month\"] = df['activation_date'].dt.day\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "russian_stop = set(stopwords.words('russian','fill'))\n",
    "\n",
    "df['desc_punctuation_cnt'] = df['description'].apply(lambda x: len(\"\".join(_ for _ in str(x) if _ in punctuation)))\n",
    "df['desc_upper_case_word_cnt'] = df['description'].apply(lambda x: len([wrd for wrd in str(x).split() if wrd.isupper()]))\n",
    "df['stopword_count'] = df['description'].apply(lambda x: len([wrd for wrd in str(x).split() if wrd.lower() in russian_stop]))\n",
    "\n",
    "df.drop([\"activation_date\",\"image\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encode Variables\n",
      "Encoding : ['region', 'city', 'parent_category_name', 'category_name', 'user_type', 'image_top_1']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEncode Variables\")\n",
    "categorical = [\"region\",\"city\",\"parent_category_name\",\"category_name\",\"user_type\",\"image_top_1\"]\n",
    "print(\"Encoding :\",categorical)\n",
    "\n",
    "# Encoder:\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in categorical:\n",
    "    df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "\n",
    "df['text_feat'] = df.apply(lambda row: ' '.join([\n",
    "    str(row['param_1']),\n",
    "    str(row['param_2']),\n",
    "    str(row['param_3'])]),axis=1) # Group Param Features into a single string\n",
    "\n",
    "df.drop([\"param_1\",\"param_2\",\"param_3\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "textfeats = [\"description\",\"text_feat\", \"title\"]\n",
    "\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str)\n",
    "    df[cols] = df[cols].astype(str).fillna('nicapotato') # WHY FILL NANS WITH NICAPOTATO?\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "\n",
    "    df[cols + '_num_chars'] = df[cols].apply(len) # Count number of Characters\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10100\n"
     ]
    }
   ],
   "source": [
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "\n",
    "\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=16000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('text_feat',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=5000,\n",
    "            preprocessor=get_col('text_feat'))),\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            max_features=5000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])\n",
    "\n",
    "\n",
    "start_vect=time.time()\n",
    "vectorizer.fit(df.to_dict('records'))\n",
    "\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "print(ready_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization Runtime: 0.05 Minutes\n"
     ]
    }
   ],
   "source": [
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "df.drop(['item_id','description','title','text_feat'],axis=1,inplace=True)\n",
    "\n",
    "df.drop('user_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>id</th>\n",
       "      <th>dullness</th>\n",
       "      <th>whiteness</th>\n",
       "      <th>average_pixel_width</th>\n",
       "      <th>blurrness</th>\n",
       "      <th>resnet50_score</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Weekd of Year</th>\n",
       "      <th>Day of Month</th>\n",
       "      <th>desc_punctuation_cnt</th>\n",
       "      <th>desc_upper_case_word_cnt</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>description_num_chars</th>\n",
       "      <th>description_num_words</th>\n",
       "      <th>description_num_unique_words</th>\n",
       "      <th>description_words_vs_unique</th>\n",
       "      <th>text_feat_num_chars</th>\n",
       "      <th>text_feat_num_words</th>\n",
       "      <th>text_feat_num_unique_words</th>\n",
       "      <th>text_feat_words_vs_unique</th>\n",
       "      <th>title_num_chars</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_num_unique_words</th>\n",
       "      <th>title_words_vs_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6.214610</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1311</td>\n",
       "      <td>3314</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>632.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>3002</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>453.89</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7.346011</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1246</td>\n",
       "      <td>1797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.59</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1654.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>478</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>4791</td>\n",
       "      <td>20.49</td>\n",
       "      <td>44.58</td>\n",
       "      <td>4.38</td>\n",
       "      <td>518.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>367</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>91.111111</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>354</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>7.313221</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>8583</td>\n",
       "      <td>1.08</td>\n",
       "      <td>87.29</td>\n",
       "      <td>4.26</td>\n",
       "      <td>383.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  region  city  parent_category_name  category_name       price  \\\n",
       "0           0      15   256                     0             40    6.214610   \n",
       "1           1       3   102                     2              4    9.210340   \n",
       "2           2      10   241                     0             43    7.346011   \n",
       "3           3      22   478                     7             33 -999.000000   \n",
       "4           4      13   354                     4             41    7.313221   \n",
       "\n",
       "   item_seq_number  user_type  image_top_1    id  dullness  whiteness  \\\n",
       "0               21          1         1311  3314     84.56       0.00   \n",
       "1                2          1          667  3002      0.00       0.00   \n",
       "2              129          0         1246  1797      0.00      87.59   \n",
       "3                2          1          228  4791     20.49      44.58   \n",
       "4               12          1         1824  8583      1.08      87.29   \n",
       "\n",
       "   average_pixel_width  blurrness  resnet50_score  Weekday  Weekd of Year  \\\n",
       "0                 4.33     632.23            0.43        1             13   \n",
       "1                 1.48     453.89            0.39        1             12   \n",
       "2                 3.98    1654.58            1.00        5             11   \n",
       "3                 4.38     518.58            0.46        2             11   \n",
       "4                 4.26     383.30            0.47        1             12   \n",
       "\n",
       "   Day of Month  desc_punctuation_cnt  desc_upper_case_word_cnt  \\\n",
       "0            28                     2                         0   \n",
       "1            21                     1                         0   \n",
       "2            18                     2                         0   \n",
       "3            15                    13                         0   \n",
       "4            21                     3                         1   \n",
       "\n",
       "   stopword_count  description_num_chars  description_num_words  \\\n",
       "0               1                     49                      7   \n",
       "1               0                     27                      3   \n",
       "2               6                    128                     23   \n",
       "3               8                    367                     45   \n",
       "4               2                     66                      9   \n",
       "\n",
       "   description_num_unique_words  description_words_vs_unique  \\\n",
       "0                             7                   100.000000   \n",
       "1                             3                   100.000000   \n",
       "2                            22                    95.652174   \n",
       "3                            41                    91.111111   \n",
       "4                             9                   100.000000   \n",
       "\n",
       "   text_feat_num_chars  text_feat_num_words  text_feat_num_unique_words  \\\n",
       "0                   17                    3                           2   \n",
       "1                   48                    7                           7   \n",
       "2                   32                    4                           4   \n",
       "3                   16                    3                           2   \n",
       "4                   30                    5                           4   \n",
       "\n",
       "   text_feat_words_vs_unique  title_num_chars  title_num_words  \\\n",
       "0                  66.666667               29                5   \n",
       "1                 100.000000               38                5   \n",
       "2                 100.000000               10                2   \n",
       "3                  66.666667               17                2   \n",
       "4                  80.000000               18                3   \n",
       "\n",
       "   title_num_unique_words  title_words_vs_unique  \n",
       "0                       5                  100.0  \n",
       "1                       5                  100.0  \n",
       "2                       2                  100.0  \n",
       "3                       2                  100.0  \n",
       "4                       3                  100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows',50, 'display.max_columns', 50):\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>dullness</th>\n",
       "      <th>whiteness</th>\n",
       "      <th>average_pixel_width</th>\n",
       "      <th>blurrness</th>\n",
       "      <th>resnet50_score</th>\n",
       "      <th>desc_punctuation_cnt</th>\n",
       "      <th>desc_upper_case_word_cnt</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>description_num_words</th>\n",
       "      <th>description_num_unique_words</th>\n",
       "      <th>description_words_vs_unique</th>\n",
       "      <th>text_feat_num_chars</th>\n",
       "      <th>text_feat_num_words</th>\n",
       "      <th>text_feat_num_unique_words</th>\n",
       "      <th>text_feat_words_vs_unique</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_num_unique_words</th>\n",
       "      <th>title_words_vs_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6.214610</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1311</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>632.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>453.89</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7.346011</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1246</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.59</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1654.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>478</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>20.49</td>\n",
       "      <td>44.58</td>\n",
       "      <td>4.38</td>\n",
       "      <td>518.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>91.111111</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>354</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>7.313221</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>1.08</td>\n",
       "      <td>87.29</td>\n",
       "      <td>4.26</td>\n",
       "      <td>383.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  city  parent_category_name  category_name       price  \\\n",
       "0      15   256                     0             40    6.214610   \n",
       "1       3   102                     2              4    9.210340   \n",
       "2      10   241                     0             43    7.346011   \n",
       "3      22   478                     7             33 -999.000000   \n",
       "4      13   354                     4             41    7.313221   \n",
       "\n",
       "   item_seq_number  user_type  image_top_1  dullness  whiteness  \\\n",
       "0               21          1         1311     84.56       0.00   \n",
       "1                2          1          667      0.00       0.00   \n",
       "2              129          0         1246      0.00      87.59   \n",
       "3                2          1          228     20.49      44.58   \n",
       "4               12          1         1824      1.08      87.29   \n",
       "\n",
       "   average_pixel_width  blurrness  resnet50_score  desc_punctuation_cnt  \\\n",
       "0                 4.33     632.23            0.43                     2   \n",
       "1                 1.48     453.89            0.39                     1   \n",
       "2                 3.98    1654.58            1.00                     2   \n",
       "3                 4.38     518.58            0.46                    13   \n",
       "4                 4.26     383.30            0.47                     3   \n",
       "\n",
       "   desc_upper_case_word_cnt  stopword_count  description_num_words  \\\n",
       "0                         0               1                      7   \n",
       "1                         0               0                      3   \n",
       "2                         0               6                     23   \n",
       "3                         0               8                     45   \n",
       "4                         1               2                      9   \n",
       "\n",
       "   description_num_unique_words  description_words_vs_unique  \\\n",
       "0                             7                   100.000000   \n",
       "1                             3                   100.000000   \n",
       "2                            22                    95.652174   \n",
       "3                            41                    91.111111   \n",
       "4                             9                   100.000000   \n",
       "\n",
       "   text_feat_num_chars  text_feat_num_words  text_feat_num_unique_words  \\\n",
       "0                   17                    3                           2   \n",
       "1                   48                    7                           7   \n",
       "2                   32                    4                           4   \n",
       "3                   16                    3                           2   \n",
       "4                   30                    5                           4   \n",
       "\n",
       "   text_feat_words_vs_unique  title_num_words  title_num_unique_words  \\\n",
       "0                  66.666667                5                       5   \n",
       "1                 100.000000                5                       5   \n",
       "2                 100.000000                2                       2   \n",
       "3                  66.666667                2                       2   \n",
       "4                  80.000000                3                       3   \n",
       "\n",
       "   title_words_vs_unique  \n",
       "0                  100.0  \n",
       "1                  100.0  \n",
       "2                  100.0  \n",
       "3                  100.0  \n",
       "4                  100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 26)\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0','Weekday','Weekd of Year','Day of Month','description_num_chars','title_num_chars','id'],axis=1,inplace=True)\n",
    "\n",
    "with pd.option_context('display.max_rows',50, 'display.max_columns', 50):\n",
    "    display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling Stage\n",
      "10100 Rows and 23022 Cols\n",
      "Feature Names Length:  23022\n"
     ]
    }
   ],
   "source": [
    "print(\"Modeling Stage\")\n",
    "#Combine Dense Features with Sparse Text Bag of Words Features\n",
    "X = hstack([csr_matrix(df.loc[df_index,:].values),ready_df[:df_index.shape[0]]]) # Sparse Matrix\n",
    "\n",
    "#testing = hstack([csr_matrix(df.loc[testdex,:].values),ready_df[traindex.shape[0]:]])\n",
    "\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "\n",
    "for shape in [X]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "#del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=100, random_state = 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler(with_mean=False)\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 0.24820717549028065\n",
      "200 0.24318084592437347\n",
      "300 0.23895234007579585\n",
      "400 0.23575404327761934\n",
      "500 0.24140817453987085\n",
      "600 0.24533566070256463\n",
      "700 0.23776091648414543\n",
      "800 0.24004064464065264\n",
      "900 0.23623558418549342\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def plot_ridge():\n",
    "    ridge_rmse = []\n",
    "    Dimension = []\n",
    "    #Dimensionality reduction using TruncatedSVD\n",
    "    for i in range(100,1000,100):\n",
    "        svd = TruncatedSVD(n_components = i,random_state=42,n_iter = 7).fit(X_train_scaled)\n",
    "        X_train_reduced = svd.transform(X_train_scaled)\n",
    "        X_test_reduced = svd.transform(X_test_scaled)\n",
    "        ridge_model = linear_model.Ridge(alpha = 5.0).fit(X_train_reduced,y_train)\n",
    "        ridge_predicted = ridge_model.predict(X_test_reduced)\n",
    "        ridge_rms = sqrt(mean_squared_error(y_test, ridge_predicted))\n",
    "    #ridge_rmse.append(ridge_rms)\n",
    "    #Dimension.append(i)\n",
    "        print (i,ridge_rms)  \n",
    "    #plt.plot(Dimension,ridge_rmse,label = \"Ridge_RMSE\")\n",
    "    #plt.ylabel(\"RMSE\")\n",
    "   # plt.xlabel(\"Dimension_Size\")\n",
    "    #plt.legend()\n",
    "\n",
    "plot_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 0.24217298214060382\n",
      "1200 0.24003459126389265\n",
      "1400 0.23978360200610027\n",
      "1600 0.24075052175474046\n",
      "1800 0.23893520863060097\n",
      "2000 0.2456604372941301\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def plot_ridge():\n",
    "    #ridge_rmse = []\n",
    "    #Dimension = []\n",
    "    #Dimensionality reduction using TruncatedSVD\n",
    "    for i in (1000,1200,1400,1600,1800,2000):    \n",
    "        svd = TruncatedSVD(n_components= i, n_iter=7, random_state=42).fit(X_train_scaled)\n",
    "        X_train_reduced = svd.transform(X_train_scaled)\n",
    "        X_test_reduced = svd.transform(X_test_scaled)\n",
    "        ridge_model = linear_model.Ridge(alpha = 5.0).fit(X_train_reduced,y_train)\n",
    "        ridge_predicted = ridge_model.predict(X_test_reduced)\n",
    "        ridge_rms = sqrt(mean_squared_error(y_test, ridge_predicted))\n",
    "        print(i,ridge_rms)\n",
    "        #ridge_rmse.append(ridge_rms)\n",
    "        #Dimension.append(i)\n",
    "        \n",
    "    #plt.plot(Dimension,ridge_rmse,label = \"Ridge_RMSE\")\n",
    "    #plt.ylabel(\"RMSE\")\n",
    "    #plt.xlabel(\"Dimension_Size\")\n",
    "    #plt.legend()\n",
    "\n",
    "plot_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 0.24566043729412906\n",
      "3000 0.25317632542749346\n",
      "4000 0.26653304615288864\n",
      "5000 0.2728843276782871\n",
      "6000 0.29207560067816213\n",
      "7000 0.3197961810175255\n",
      "8000 0.3655944843802622\n",
      "9000 0.4243299652574728\n",
      "10000 0.5937634340700518\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def plot_ridge():\n",
    "    ridge_rmse = []\n",
    "    Dimension = []\n",
    "    #Dimensionality reduction using TruncatedSVD\n",
    "    for i in range(2000,11000,1000):\n",
    "        svd = TruncatedSVD(n_components = i,random_state=42,n_iter = 7).fit(X_train_scaled)\n",
    "        X_train_reduced = svd.transform(X_train_scaled)\n",
    "        X_test_reduced = svd.transform(X_test_scaled)\n",
    "        ridge_model = linear_model.Ridge(alpha = 5.0).fit(X_train_reduced,y_train)\n",
    "        ridge_predicted = ridge_model.predict(X_test_reduced)\n",
    "        ridge_rms = sqrt(mean_squared_error(y_test, ridge_predicted))\n",
    "    #ridge_rmse.append(ridge_rms)\n",
    "    #Dimension.append(i)\n",
    "        print (i,ridge_rms)  \n",
    "    #plt.plot(Dimension,ridge_rmse,label = \"Ridge_RMSE\")\n",
    "    #plt.ylabel(\"RMSE\")\n",
    "   # plt.xlabel(\"Dimension_Size\")\n",
    "    #plt.legend()\n",
    "\n",
    "plot_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 0.5937634340700386\n",
      "14000 0.5937634340699735\n",
      "16000 0.5937634340700452\n",
      "18000 0.5937634340700685\n",
      "20000 0.5937634340700713\n",
      "22000 0.5937634340700371\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def plot_ridge():\n",
    "    ridge_rmse = []\n",
    "    Dimension = []\n",
    "    #Dimensionality reduction using TruncatedSVD\n",
    "    for i in (12000,14000,16000,18000,20000,22000):\n",
    "        svd = TruncatedSVD(n_components = i,random_state=42,n_iter = 7).fit(X_train_scaled)\n",
    "        X_train_reduced = svd.transform(X_train_scaled)\n",
    "        X_test_reduced = svd.transform(X_test_scaled)\n",
    "        ridge_model = linear_model.Ridge(alpha = 5.0).fit(X_train_reduced,y_train)\n",
    "        ridge_predicted = ridge_model.predict(X_test_reduced)\n",
    "        ridge_rms = sqrt(mean_squared_error(y_test, ridge_predicted))\n",
    "    #ridge_rmse.append(ridge_rms)\n",
    "    #Dimension.append(i)\n",
    "        print (i,ridge_rms)  \n",
    "    #plt.plot(Dimension,ridge_rmse,label = \"Ridge_RMSE\")\n",
    "    #plt.ylabel(\"RMSE\")\n",
    "   # plt.xlabel(\"Dimension_Size\")\n",
    "    #plt.legend()\n",
    "\n",
    "plot_ridge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4110826517302157\n",
      "[  804   889  1069  1342  2537  2600  3131  4736  5434  6679  6798  6966\n",
      "  8420  8834  9268  9580  9702  9918 10346 10557 10658 10762 10781 11008\n",
      " 11142 11534 12060 13855 14061 14244 14250 14710 14778 15002 15291 15610\n",
      " 15661 15853 18412 18705 18706 18853 18928 18951 19378 19799 19851 19866\n",
      " 19971 20447 20466 20620 20703 20794 20831 20919 21115 21221 21427 21428\n",
      " 21663 21752 21788 21941 21959 21977 21998 22129 22224 22273 22395 22414\n",
      " 22459 22469 22507 22800]\n",
      "[3232 3814 4127]\n",
      "[804, 889, 1069, 1342, 2537, 2600, 3131, 4736, 5434, 6679, 6798, 6966, 8420, 8834, 9268, 9580, 9702, 9918, 10346, 10557, 10658, 10762, 10781, 11008, 11142, 11534, 12060, 13855, 14061, 14244, 14250, 14710, 14778, 15002, 15291, 15610, 15661, 15853, 18412, 18705, 18706, 18853, 18928, 18951, 19378, 19799, 19851, 19866, 19971, 20447, 20466, 20620, 20703, 20794, 20831, 20919, 21115, 21221, 21427, 21428, 21663, 21752, 21788, 21941, 21959, 21977, 21998, 22129, 22224, 22273, 22395, 22414, 22459, 22469, 22507, 22800, 3232, 3814, 4127]\n",
      "description__380\n",
      "description__42 43\n",
      "description__5см\n",
      "description__acoola\n",
      "description__аппарат\n",
      "description__б нормальном\n",
      "description__ванную\n",
      "description__демисезон\n",
      "description__жалко\n",
      "description__квадратная\n",
      "description__кирова\n",
      "description__кожа черная\n",
      "description__матрас\n",
      "description__мокасины\n",
      "description__наушники\n",
      "description__новые размер\n",
      "description__носком\n",
      "description__обуты\n",
      "description__осень натуральная\n",
      "description__отл сост\n",
      "description__отс\n",
      "description__очень приятная\n",
      "description__очень хорошее\n",
      "description__перчатки\n",
      "description__плита\n",
      "description__полуботинки\n",
      "description__продам детский\n",
      "description__состоянии очень\n",
      "description__стала мала\n",
      "description__струны\n",
      "description__стула\n",
      "description__тумбу\n",
      "description__угловой\n",
      "description__утюг\n",
      "description__ходунки\n",
      "description__чехлом\n",
      "description__чёрные\n",
      "description__эксплуатировался\n",
      "title__35 36\n",
      "title__86\n",
      "title__86 92\n",
      "title__capella\n",
      "title__dior\n",
      "title__ecco\n",
      "title__philips\n",
      "title__беби\n",
      "title__большого\n",
      "title__босоножки новые\n",
      "title__велосипед\n",
      "title__жилет мальчика\n",
      "title__замок\n",
      "title__качалка\n",
      "title__керри\n",
      "title__коляска девочки\n",
      "title__комнатные\n",
      "title__котенок\n",
      "title__летняя коляска\n",
      "title__матрасом\n",
      "title__нан\n",
      "title__напольная\n",
      "title__отдам\n",
      "title__пеленки\n",
      "title__пк\n",
      "title__принцессы\n",
      "title__продам\n",
      "title__продам диван\n",
      "title__продам монитор\n",
      "title__рама\n",
      "title__самовар\n",
      "title__сборе\n",
      "title__состояние\n",
      "title__спортивная\n",
      "title__стиральная машинка\n",
      "title__стол\n",
      "title__сумка женская\n",
      "title__холодильная витрина\n",
      "description__велосипед б\n",
      "description__вторая\n",
      "description__гараже\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def plot_ridge():\n",
    "    \n",
    "    #Dimensionality reduction using TruncatedSVD\n",
    "    important_coefs =[]\n",
    "    ridge_model = linear_model.Ridge(alpha = 5.0).fit(X_train_scaled,y_train)\n",
    "    ridge_predicted = ridge_model.predict(X_test_scaled)\n",
    "    ridge_rms = sqrt(mean_squared_error(y_test, ridge_predicted))\n",
    "    #ridge_rmse.append(ridge_rms)\n",
    "    #Dimension.append(i)\n",
    "    print (ridge_rms)\n",
    "    \n",
    "    coef = ridge_model.coef_\n",
    "    plt.plot(coef)\n",
    "    for x in np.where(coef>0.007):\n",
    "        print(x)\n",
    "        for i in x:\n",
    "            important_coefs.append(i)\n",
    "    for x in np.where(coef<-0.007):\n",
    "        print(x)\n",
    "        for i in x:\n",
    "            important_coefs.append(i)\n",
    "        \n",
    "    print(important_coefs)\n",
    "    \n",
    "    for i in important_coefs:\n",
    "        print(tfvocab[i])\n",
    "    \n",
    "    \n",
    "plot_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41079761523667696\n",
      "0.41070719267560213\n",
      "0.4110070729369312\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "def plot_ridge():\n",
    "    \n",
    "    #Dimensionality reduction using TruncatedSVD\n",
    "    \n",
    "    #svd = TruncatedSVD(n_components = 4000,random_state=42,n_iter = 7).fit(X_train_scaled)\n",
    "    #X_train_reduced = svd.transform(X_train_scaled)\n",
    "    #X_test_reduced = svd.transform(X_test_scaled)\n",
    "    for i in (5.0,5.5,6.0):\n",
    "        ridge_model = linear_model.Ridge(alpha = i).fit(X_train_scaled,y_train)\n",
    "        ridge_predicted = ridge_model.predict(X_test_scaled)\n",
    "        ridge_rms = sqrt(mean_squared_error(y_test, ridge_predicted))\n",
    "    #ridge_rmse.append(ridge_rms)\n",
    "    #Dimension.append(i)\n",
    "        print (ridge_rms)  \n",
    "    #plt.plot(Dimension,ridge_rmse,label = \"Ridge_RMSE\")\n",
    "    #plt.ylabel(\"RMSE\")\n",
    "   # plt.xlabel(\"Dimension_Size\")\n",
    "    #plt.legend()\n",
    "    #coef = ridge_model.coef_\n",
    "    #plt.plot(coef)\n",
    "    #for x in np.where(coef<-0.005):\n",
    "        #print(x) \n",
    "    \n",
    "plot_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
