{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/zyc62/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import time\n",
    "notebookstart= time.time()\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# Gradient Boosting\n",
    "#import lightgbm as lgb\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "#HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('demo10100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Load Stage\n",
      "RangeIndex(start=0, stop=10100, step=1)\n",
      "[nltk_data] Downloading package stopwords to /home/zyc62/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Load Stage\")\n",
    "df = pd.read_csv('demo10100.csv',parse_dates = [\"activation_date\"])\n",
    "df_index = df.index\n",
    "print(df_index)\n",
    "\n",
    "#testing = pd.read_csv('test.csv',parse_dates = [\"activation_date\"])\n",
    "#testdex = testing.index\n",
    "#test_item = testing['item_id']\n",
    "\n",
    "y = df['deal_probability'].copy()\n",
    "df.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "\n",
    "#print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
    "#print('Test shape: {} Rows, {} Columns'.format(*testing.shape))\n",
    "\n",
    "df[\"price\"] = np.log(df[\"price\"]+0.001)               # filling in NaN's\n",
    "df[\"price\"].fillna(-999,inplace=True)\n",
    "df[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "df['param_1'].fillna('fill',inplace=True)\n",
    "df['param_2'].fillna('fill',inplace=True)\n",
    "df['param_3'].fillna('fill',inplace=True)\n",
    "\n",
    "df[\"Weekday\"] = df['activation_date'].dt.weekday\n",
    "df[\"Weekd of Year\"] = df['activation_date'].dt.week\n",
    "df[\"Day of Month\"] = df['activation_date'].dt.day\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "russian_stop = set(stopwords.words('russian','fill'))\n",
    "\n",
    "df['desc_punctuation_cnt'] = df['description'].apply(lambda x: len(\"\".join(_ for _ in str(x) if _ in punctuation)))\n",
    "df['desc_upper_case_word_cnt'] = df['description'].apply(lambda x: len([wrd for wrd in str(x).split() if wrd.isupper()]))\n",
    "df['stopword_count'] = df['description'].apply(lambda x: len([wrd for wrd in str(x).split() if wrd.lower() in russian_stop]))\n",
    "\n",
    "df.drop([\"activation_date\",\"image\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encode Variables\n",
      "Encoding : ['region', 'city', 'parent_category_name', 'category_name', 'user_type', 'image_top_1']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEncode Variables\")\n",
    "categorical = [\"region\",\"city\",\"parent_category_name\",\"category_name\",\"user_type\",\"image_top_1\"]\n",
    "print(\"Encoding :\",categorical)\n",
    "\n",
    "# Encoder:\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in categorical:\n",
    "    df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "\n",
    "df['text_feat'] = df.apply(lambda row: ' '.join([\n",
    "    str(row['param_1']),\n",
    "    str(row['param_2']),\n",
    "    str(row['param_3'])]),axis=1) # Group Param Features into a single string\n",
    "\n",
    "df.drop([\"param_1\",\"param_2\",\"param_3\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "textfeats = [\"description\",\"text_feat\", \"title\"]\n",
    "\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str)\n",
    "    df[cols] = df[cols].astype(str).fillna('nicapotato') # WHY FILL NANS WITH NICAPOTATO?\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "\n",
    "    df[cols + '_num_chars'] = df[cols].apply(len) # Count number of Characters\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10100\n"
     ]
    }
   ],
   "source": [
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "\n",
    "\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=16000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('text_feat',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=5000,\n",
    "            preprocessor=get_col('text_feat'))),\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            max_features=5000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])\n",
    "\n",
    "\n",
    "start_vect=time.time()\n",
    "vectorizer.fit(df.to_dict('records'))\n",
    "\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "print(ready_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization Runtime: 0.05 Minutes\n"
     ]
    }
   ],
   "source": [
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "df.drop(['item_id','description','title','text_feat'],axis=1,inplace=True)\n",
    "\n",
    "df.drop('user_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>id</th>\n",
       "      <th>dullness</th>\n",
       "      <th>whiteness</th>\n",
       "      <th>average_pixel_width</th>\n",
       "      <th>blurrness</th>\n",
       "      <th>resnet50_score</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Weekd of Year</th>\n",
       "      <th>Day of Month</th>\n",
       "      <th>desc_punctuation_cnt</th>\n",
       "      <th>desc_upper_case_word_cnt</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>description_num_chars</th>\n",
       "      <th>description_num_words</th>\n",
       "      <th>description_num_unique_words</th>\n",
       "      <th>description_words_vs_unique</th>\n",
       "      <th>text_feat_num_chars</th>\n",
       "      <th>text_feat_num_words</th>\n",
       "      <th>text_feat_num_unique_words</th>\n",
       "      <th>text_feat_words_vs_unique</th>\n",
       "      <th>title_num_chars</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_num_unique_words</th>\n",
       "      <th>title_words_vs_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6.214610</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1311</td>\n",
       "      <td>3314</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>632.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>3002</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>453.89</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7.346011</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1246</td>\n",
       "      <td>1797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.59</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1654.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>478</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>4791</td>\n",
       "      <td>20.49</td>\n",
       "      <td>44.58</td>\n",
       "      <td>4.38</td>\n",
       "      <td>518.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>367</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>91.111111</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>354</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>7.313221</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>8583</td>\n",
       "      <td>1.08</td>\n",
       "      <td>87.29</td>\n",
       "      <td>4.26</td>\n",
       "      <td>383.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  region  city  parent_category_name  category_name       price  \\\n",
       "0           0      15   256                     0             40    6.214610   \n",
       "1           1       3   102                     2              4    9.210340   \n",
       "2           2      10   241                     0             43    7.346011   \n",
       "3           3      22   478                     7             33 -999.000000   \n",
       "4           4      13   354                     4             41    7.313221   \n",
       "\n",
       "   item_seq_number  user_type  image_top_1    id  dullness  whiteness  \\\n",
       "0               21          1         1311  3314     84.56       0.00   \n",
       "1                2          1          667  3002      0.00       0.00   \n",
       "2              129          0         1246  1797      0.00      87.59   \n",
       "3                2          1          228  4791     20.49      44.58   \n",
       "4               12          1         1824  8583      1.08      87.29   \n",
       "\n",
       "   average_pixel_width  blurrness  resnet50_score  Weekday  Weekd of Year  \\\n",
       "0                 4.33     632.23            0.43        1             13   \n",
       "1                 1.48     453.89            0.39        1             12   \n",
       "2                 3.98    1654.58            1.00        5             11   \n",
       "3                 4.38     518.58            0.46        2             11   \n",
       "4                 4.26     383.30            0.47        1             12   \n",
       "\n",
       "   Day of Month  desc_punctuation_cnt  desc_upper_case_word_cnt  \\\n",
       "0            28                     2                         0   \n",
       "1            21                     1                         0   \n",
       "2            18                     2                         0   \n",
       "3            15                    13                         0   \n",
       "4            21                     3                         1   \n",
       "\n",
       "   stopword_count  description_num_chars  description_num_words  \\\n",
       "0               1                     49                      7   \n",
       "1               0                     27                      3   \n",
       "2               6                    128                     23   \n",
       "3               8                    367                     45   \n",
       "4               2                     66                      9   \n",
       "\n",
       "   description_num_unique_words  description_words_vs_unique  \\\n",
       "0                             7                   100.000000   \n",
       "1                             3                   100.000000   \n",
       "2                            22                    95.652174   \n",
       "3                            41                    91.111111   \n",
       "4                             9                   100.000000   \n",
       "\n",
       "   text_feat_num_chars  text_feat_num_words  text_feat_num_unique_words  \\\n",
       "0                   17                    3                           2   \n",
       "1                   48                    7                           7   \n",
       "2                   32                    4                           4   \n",
       "3                   16                    3                           2   \n",
       "4                   30                    5                           4   \n",
       "\n",
       "   text_feat_words_vs_unique  title_num_chars  title_num_words  \\\n",
       "0                  66.666667               29                5   \n",
       "1                 100.000000               38                5   \n",
       "2                 100.000000               10                2   \n",
       "3                  66.666667               17                2   \n",
       "4                  80.000000               18                3   \n",
       "\n",
       "   title_num_unique_words  title_words_vs_unique  \n",
       "0                       5                  100.0  \n",
       "1                       5                  100.0  \n",
       "2                       2                  100.0  \n",
       "3                       2                  100.0  \n",
       "4                       3                  100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows',50, 'display.max_columns', 50):\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>dullness</th>\n",
       "      <th>whiteness</th>\n",
       "      <th>average_pixel_width</th>\n",
       "      <th>blurrness</th>\n",
       "      <th>resnet50_score</th>\n",
       "      <th>desc_punctuation_cnt</th>\n",
       "      <th>desc_upper_case_word_cnt</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>description_num_words</th>\n",
       "      <th>description_num_unique_words</th>\n",
       "      <th>description_words_vs_unique</th>\n",
       "      <th>text_feat_num_chars</th>\n",
       "      <th>text_feat_num_words</th>\n",
       "      <th>text_feat_num_unique_words</th>\n",
       "      <th>text_feat_words_vs_unique</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_num_unique_words</th>\n",
       "      <th>title_words_vs_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6.214610</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1311</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>632.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>453.89</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7.346011</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1246</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.59</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1654.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>478</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>20.49</td>\n",
       "      <td>44.58</td>\n",
       "      <td>4.38</td>\n",
       "      <td>518.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>91.111111</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>354</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>7.313221</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>1.08</td>\n",
       "      <td>87.29</td>\n",
       "      <td>4.26</td>\n",
       "      <td>383.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  city  parent_category_name  category_name       price  \\\n",
       "0      15   256                     0             40    6.214610   \n",
       "1       3   102                     2              4    9.210340   \n",
       "2      10   241                     0             43    7.346011   \n",
       "3      22   478                     7             33 -999.000000   \n",
       "4      13   354                     4             41    7.313221   \n",
       "\n",
       "   item_seq_number  user_type  image_top_1  dullness  whiteness  \\\n",
       "0               21          1         1311     84.56       0.00   \n",
       "1                2          1          667      0.00       0.00   \n",
       "2              129          0         1246      0.00      87.59   \n",
       "3                2          1          228     20.49      44.58   \n",
       "4               12          1         1824      1.08      87.29   \n",
       "\n",
       "   average_pixel_width  blurrness  resnet50_score  desc_punctuation_cnt  \\\n",
       "0                 4.33     632.23            0.43                     2   \n",
       "1                 1.48     453.89            0.39                     1   \n",
       "2                 3.98    1654.58            1.00                     2   \n",
       "3                 4.38     518.58            0.46                    13   \n",
       "4                 4.26     383.30            0.47                     3   \n",
       "\n",
       "   desc_upper_case_word_cnt  stopword_count  description_num_words  \\\n",
       "0                         0               1                      7   \n",
       "1                         0               0                      3   \n",
       "2                         0               6                     23   \n",
       "3                         0               8                     45   \n",
       "4                         1               2                      9   \n",
       "\n",
       "   description_num_unique_words  description_words_vs_unique  \\\n",
       "0                             7                   100.000000   \n",
       "1                             3                   100.000000   \n",
       "2                            22                    95.652174   \n",
       "3                            41                    91.111111   \n",
       "4                             9                   100.000000   \n",
       "\n",
       "   text_feat_num_chars  text_feat_num_words  text_feat_num_unique_words  \\\n",
       "0                   17                    3                           2   \n",
       "1                   48                    7                           7   \n",
       "2                   32                    4                           4   \n",
       "3                   16                    3                           2   \n",
       "4                   30                    5                           4   \n",
       "\n",
       "   text_feat_words_vs_unique  title_num_words  title_num_unique_words  \\\n",
       "0                  66.666667                5                       5   \n",
       "1                 100.000000                5                       5   \n",
       "2                 100.000000                2                       2   \n",
       "3                  66.666667                2                       2   \n",
       "4                  80.000000                3                       3   \n",
       "\n",
       "   title_words_vs_unique  \n",
       "0                  100.0  \n",
       "1                  100.0  \n",
       "2                  100.0  \n",
       "3                  100.0  \n",
       "4                  100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 26)\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0','Weekday','Weekd of Year','Day of Month','description_num_chars','title_num_chars','id'],axis=1,inplace=True)\n",
    "\n",
    "with pd.option_context('display.max_rows',50, 'display.max_columns', 50):\n",
    "    display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling Stage\n",
      "(10100, 22996)\n",
      "10100 Rows and 23022 Cols\n",
      "Feature Names Length:  23022\n"
     ]
    }
   ],
   "source": [
    "print(\"Modeling Stage\")\n",
    "#Combine Dense Features with Sparse Text Bag of Words Features\n",
    "X = hstack([csr_matrix(df.loc[df_index,:].values),ready_df[:df_index.shape[0]]]) # Sparse Matrix\n",
    "\n",
    "\n",
    "#testing = hstack([csr_matrix(df.loc[testdex,:].values),ready_df[traindex.shape[0]:]])\n",
    "\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "\n",
    "x = ready_df[:df_index.shape[0]]\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "for shape in [X]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "#del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 400)\n",
      "(10100, 426)\n",
      "0.25201063261886825\n",
      "(10100, 500)\n",
      "(10100, 526)\n",
      "0.24777222486180134\n",
      "(10100, 600)\n",
      "(10100, 626)\n",
      "0.2441487238712897\n",
      "(10100, 700)\n",
      "(10100, 726)\n",
      "0.2386257458670039\n",
      "(10100, 800)\n",
      "(10100, 826)\n",
      "0.24732121244978422\n",
      "(10100, 1000)\n",
      "(10100, 1026)\n",
      "0.2507018392160965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for i in (400,500,600,700,800,1000):\n",
    "    svd = TruncatedSVD(n_components= i, n_iter=7, random_state=42).fit(x)\n",
    "    x_reduced = svd.transform(x)\n",
    "    print(x_reduced.shape)   \n",
    "    X1 = hstack([csr_matrix(df.loc[df_index,:].values),x_reduced[:df_index.shape[0]]]) # Sparse Matrix\n",
    "    print(X1.shape)\n",
    "#tfvocab = df.columns.tolist() + tfvocab\n",
    "\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size = 100, random_state = 23)\n",
    "\n",
    "\n",
    "    ss = StandardScaler(with_mean=False)\n",
    "    X1_train_scaled = ss.fit_transform(X1_train)\n",
    "    X1_test_scaled = ss.transform(X1_test)\n",
    "\n",
    "\n",
    "\n",
    "    def plot_ridge():\n",
    "        ridge_model = linear_model.Ridge(alpha = 5.0).fit(X1_train_scaled,y1_train)\n",
    "        ridge_predicted = ridge_model.predict(X1_test_scaled)\n",
    "        ridge_rms = sqrt(mean_squared_error(y1_test, ridge_predicted))\n",
    "    \n",
    "        print (ridge_rms)  \n",
    "    \n",
    "\n",
    "    plot_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 1200)\n",
      "(10100, 1226)\n",
      "0.2577141240946108\n",
      "(10100, 1400)\n",
      "(10100, 1426)\n",
      "0.26436129216145415\n",
      "(10100, 1600)\n",
      "(10100, 1626)\n",
      "0.26899949346102237\n",
      "(10100, 1800)\n",
      "(10100, 1826)\n",
      "0.27406335710519486\n",
      "(10100, 2000)\n",
      "(10100, 2026)\n",
      "0.2814122468186412\n",
      "(10100, 2500)\n",
      "(10100, 2526)\n",
      "0.2884359214103392\n",
      "(10100, 3000)\n",
      "(10100, 3026)\n",
      "0.2981659903801435\n",
      "(10100, 4000)\n",
      "(10100, 4026)\n",
      "0.3172618121565679\n",
      "(10100, 5000)\n",
      "(10100, 5026)\n",
      "0.4559833761218537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "for i in (1200,1400,1600,1800,2000,2500,3000,4000,5000):\n",
    "    svd = TruncatedSVD(n_components= i, n_iter=7, random_state=42).fit(x)\n",
    "    x_reduced = svd.transform(x)\n",
    "    print(x_reduced.shape)   \n",
    "    X1 = hstack([csr_matrix(df.loc[df_index,:].values),x_reduced[:df_index.shape[0]]]) # Sparse Matrix\n",
    "    print(X1.shape)\n",
    "#tfvocab = df.columns.tolist() + tfvocab\n",
    "\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size = 100, random_state = 23)\n",
    "\n",
    "\n",
    "    ss = StandardScaler(with_mean=False)\n",
    "    X1_train_scaled = ss.fit_transform(X1_train)\n",
    "    X1_test_scaled = ss.transform(X1_test)\n",
    "\n",
    "\n",
    "\n",
    "    def plot_ridge():\n",
    "        ridge_model = linear_model.Ridge(alpha = 5.0).fit(X1_train_scaled,y1_train)\n",
    "        ridge_predicted = ridge_model.predict(X1_test_scaled)\n",
    "        ridge_rms = sqrt(mean_squared_error(y1_test, ridge_predicted))\n",
    "    \n",
    "        print (ridge_rms)  \n",
    "    \n",
    "    \n",
    "    plot_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 26)\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df_index,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2576796538700181\n"
     ]
    }
   ],
   "source": [
    "x26=df.loc[df_index,:]\n",
    "X26_train, X26_test, y26_train, y26_test = train_test_split(x26, y, test_size = 100, random_state = 23)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler(with_mean=False)\n",
    "X26_train_scaled = ss.fit_transform(X26_train)\n",
    "X26_test_scaled = ss.transform(X26_test)\n",
    "\n",
    "\n",
    "def plot_ridge():\n",
    "    ridge_model = linear_model.Ridge(alpha = 5.0).fit(X26_train_scaled,y26_train)\n",
    "    ridge_predicted = ridge_model.predict(X26_test_scaled)\n",
    "    ridge_rms = sqrt(mean_squared_error(y26_test, ridge_predicted))\n",
    "    \n",
    "    print (ridge_rms)  \n",
    "plot_ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
