{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>id</th>\n",
       "      <th>dullness</th>\n",
       "      <th>whiteness</th>\n",
       "      <th>average_pixel_width</th>\n",
       "      <th>blurrness</th>\n",
       "      <th>resnet50_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>e04828936fc5</td>\n",
       "      <td>2fce002a0d21</td>\n",
       "      <td>Пермский край</td>\n",
       "      <td>Кунгур</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Телефоны</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Samsung galaxy s2 на запчасти</td>\n",
       "      <td>Samsung galaxy s2 на запчасти. Неисправна память.</td>\n",
       "      <td>500.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>Private</td>\n",
       "      <td>00d4b4267560d6db37b24c3b6f6390d414f177fb8b70c9...</td>\n",
       "      <td>2932.0</td>\n",
       "      <td>0.76786</td>\n",
       "      <td>3314</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>632.23</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9b663721150e</td>\n",
       "      <td>715477fb76ad</td>\n",
       "      <td>Владимирская область</td>\n",
       "      <td>Владимир</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Бытовая техника</td>\n",
       "      <td>Для кухни</td>\n",
       "      <td>Холодильники и морозильные камеры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Холодильник однокамерный pozis - RS411</td>\n",
       "      <td>Новый, габариты 850х540х550</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-21</td>\n",
       "      <td>Private</td>\n",
       "      <td>005b26f685f0775460419064a977642f8b305fab46b239...</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3002</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>453.89</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dd768b311a3a</td>\n",
       "      <td>de5e9cda4fb7</td>\n",
       "      <td>Красноярский край</td>\n",
       "      <td>Красноярск</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Товары для компьютера</td>\n",
       "      <td>Комплектующие</td>\n",
       "      <td>Жёсткие диски</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Продам hdd</td>\n",
       "      <td>продам hdd 1000tb есть 3 переназначеных сектор...</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>129</td>\n",
       "      <td>2017-03-18</td>\n",
       "      <td>Company</td>\n",
       "      <td>01294414ab83bcf6a288a330c66cedba61a047f970d036...</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.59</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1654.58</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45a4b99b56a5</td>\n",
       "      <td>d7b6b7b7bd2a</td>\n",
       "      <td>Тульская область</td>\n",
       "      <td>Тула</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложение услуг</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Такелажные работы</td>\n",
       "      <td>Выполняем такелажные работы. Погрузка, разгруз...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-15</td>\n",
       "      <td>Private</td>\n",
       "      <td>01d6dbc1125760a39a29195754ba7c02caa6998634ecd6...</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4791</td>\n",
       "      <td>20.49</td>\n",
       "      <td>44.58</td>\n",
       "      <td>4.38</td>\n",
       "      <td>518.58</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a23da558a1ea</td>\n",
       "      <td>54a570932c79</td>\n",
       "      <td>Омская область</td>\n",
       "      <td>Омск</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Товары для кормления</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стул для кормления</td>\n",
       "      <td>Продам стул для кормления. В хорошем состоянии...</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-03-21</td>\n",
       "      <td>Private</td>\n",
       "      <td>006483c6a6fe0310307a160b44091a68884101e2eb74ce...</td>\n",
       "      <td>811.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8583</td>\n",
       "      <td>1.08</td>\n",
       "      <td>87.29</td>\n",
       "      <td>4.26</td>\n",
       "      <td>383.30</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       item_id       user_id                region        city  \\\n",
       "0           0  e04828936fc5  2fce002a0d21         Пермский край      Кунгур   \n",
       "1           1  9b663721150e  715477fb76ad  Владимирская область    Владимир   \n",
       "2           2  dd768b311a3a  de5e9cda4fb7     Красноярский край  Красноярск   \n",
       "3           3  45a4b99b56a5  d7b6b7b7bd2a      Тульская область        Тула   \n",
       "4           4  a23da558a1ea  54a570932c79        Омская область        Омск   \n",
       "\n",
       "  parent_category_name               category_name               param_1  \\\n",
       "0  Бытовая электроника                    Телефоны               Samsung   \n",
       "1      Для дома и дачи             Бытовая техника             Для кухни   \n",
       "2  Бытовая электроника       Товары для компьютера         Комплектующие   \n",
       "3               Услуги           Предложение услуг                Другое   \n",
       "4          Личные вещи  Товары для детей и игрушки  Товары для кормления   \n",
       "\n",
       "                             param_2 param_3  \\\n",
       "0                                NaN     NaN   \n",
       "1  Холодильники и морозильные камеры     NaN   \n",
       "2                      Жёсткие диски     NaN   \n",
       "3                                NaN     NaN   \n",
       "4                                NaN     NaN   \n",
       "\n",
       "                                    title  \\\n",
       "0           Samsung galaxy s2 на запчасти   \n",
       "1  Холодильник однокамерный pozis - RS411   \n",
       "2                              Продам hdd   \n",
       "3                       Такелажные работы   \n",
       "4                      Стул для кормления   \n",
       "\n",
       "                                         description    price  \\\n",
       "0  Samsung galaxy s2 на запчасти. Неисправна память.    500.0   \n",
       "1                        Новый, габариты 850х540х550  10000.0   \n",
       "2  продам hdd 1000tb есть 3 переназначеных сектор...   1550.0   \n",
       "3  Выполняем такелажные работы. Погрузка, разгруз...      NaN   \n",
       "4  Продам стул для кормления. В хорошем состоянии...   1500.0   \n",
       "\n",
       "   item_seq_number activation_date user_type  \\\n",
       "0               21      2017-03-28   Private   \n",
       "1                2      2017-03-21   Private   \n",
       "2              129      2017-03-18   Company   \n",
       "3                2      2017-03-15   Private   \n",
       "4               12      2017-03-21   Private   \n",
       "\n",
       "                                               image  image_top_1  \\\n",
       "0  00d4b4267560d6db37b24c3b6f6390d414f177fb8b70c9...       2932.0   \n",
       "1  005b26f685f0775460419064a977642f8b305fab46b239...       1884.0   \n",
       "2  01294414ab83bcf6a288a330c66cedba61a047f970d036...       2860.0   \n",
       "3  01d6dbc1125760a39a29195754ba7c02caa6998634ecd6...       1283.0   \n",
       "4  006483c6a6fe0310307a160b44091a68884101e2eb74ce...        811.0   \n",
       "\n",
       "   deal_probability    id  dullness  whiteness  average_pixel_width  \\\n",
       "0           0.76786  3314     84.56       0.00                 4.33   \n",
       "1           0.00000  3002      0.00       0.00                 1.48   \n",
       "2           0.00000  1797      0.00      87.59                 3.98   \n",
       "3           0.00000  4791     20.49      44.58                 4.38   \n",
       "4           0.00000  8583      1.08      87.29                 4.26   \n",
       "\n",
       "   blurrness  resnet50_score  \n",
       "0     632.23            0.43  \n",
       "1     453.89            0.39  \n",
       "2    1654.58            1.00  \n",
       "3     518.58            0.46  \n",
       "4     383.30            0.47  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo shape: 10100 Rows, 25 Columns\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/projectMachine/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('demo10100.csv') #textual data\n",
    "with pd.option_context('display.max_rows',50, 'display.max_columns', 50):\n",
    "    display(df.head())\n",
    "    \n",
    "print('Demo shape: {} Rows, {} Columns'.format(*df.shape))\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import time\n",
    "notebookstart= time.time()\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "# Models Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "# Gradient Boosting\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Tf-Idf\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "#HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Load Stage\n",
      "RangeIndex(start=0, stop=10100, step=1)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/projectMachine/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Load Stage\")\n",
    "df = pd.read_csv('demo10100.csv',parse_dates = [\"activation_date\"])\n",
    "df_index = df.index\n",
    "print(df_index)\n",
    "\n",
    "#testing = pd.read_csv('test.csv',parse_dates = [\"activation_date\"])\n",
    "#testdex = testing.index\n",
    "#test_item = testing['item_id']\n",
    "\n",
    "y = df['deal_probability'].copy()\n",
    "df.drop(\"deal_probability\",axis=1, inplace=True)\n",
    "\n",
    "#print('Train shape: {} Rows, {} Columns'.format(*training.shape))\n",
    "#print('Test shape: {} Rows, {} Columns'.format(*testing.shape))\n",
    "\n",
    "df[\"price\"] = np.log(df[\"price\"]+0.001)               # filling in NaN's\n",
    "df[\"price\"].fillna(-999,inplace=True)\n",
    "df[\"image_top_1\"].fillna(-999,inplace=True)\n",
    "df['param_1'].fillna('fill',inplace=True)\n",
    "df['param_2'].fillna('fill',inplace=True)\n",
    "df['param_3'].fillna('fill',inplace=True)\n",
    "\n",
    "df[\"Weekday\"] = df['activation_date'].dt.weekday\n",
    "df[\"Weekd of Year\"] = df['activation_date'].dt.week\n",
    "df[\"Day of Month\"] = df['activation_date'].dt.day\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "russian_stop = set(stopwords.words('russian','fill'))\n",
    "\n",
    "df['desc_punctuation_cnt'] = df['description'].apply(lambda x: len(\"\".join(_ for _ in str(x) if _ in punctuation)))\n",
    "df['desc_upper_case_word_cnt'] = df['description'].apply(lambda x: len([wrd for wrd in str(x).split() if wrd.isupper()]))\n",
    "df['stopword_count'] = df['description'].apply(lambda x: len([wrd for wrd in str(x).split() if wrd.lower() in russian_stop]))\n",
    "\n",
    "df.drop([\"activation_date\",\"image\"],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encode Variables\n",
      "Encoding : ['region', 'city', 'parent_category_name', 'category_name', 'user_type', 'image_top_1']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEncode Variables\")\n",
    "categorical = [\"region\",\"city\",\"parent_category_name\",\"category_name\",\"user_type\",\"image_top_1\"]\n",
    "print(\"Encoding :\",categorical)\n",
    "\n",
    "# Encoder:\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "for col in categorical:\n",
    "    df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "\n",
    "df['text_feat'] = df.apply(lambda row: ' '.join([\n",
    "    str(row['param_1']),\n",
    "    str(row['param_2']),\n",
    "    str(row['param_3'])]),axis=1) # Group Param Features into a single string\n",
    "\n",
    "df.drop([\"param_1\",\"param_2\",\"param_3\"],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "textfeats = [\"description\",\"text_feat\", \"title\"]\n",
    "\n",
    "for cols in textfeats:\n",
    "    df[cols] = df[cols].astype(str)\n",
    "    df[cols] = df[cols].astype(str).fillna('nicapotato') # WHY FILL NANS WITH NICAPOTATO?\n",
    "    df[cols] = df[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    "\n",
    "    df[cols + '_num_chars'] = df[cols].apply(len) # Count number of Characters\n",
    "    df[cols + '_num_words'] = df[cols].apply(lambda comment: len(comment.split())) # Count number of Words\n",
    "    df[cols + '_num_unique_words'] = df[cols].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df[cols + '_words_vs_unique'] = df[cols+'_num_unique_words'] / df[cols+'_num_words'] * 100 # Count Unique Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10100\n"
     ]
    }
   ],
   "source": [
    "tfidf_para = {\n",
    "    \"stop_words\": russian_stop,\n",
    "    \"analyzer\": 'word',\n",
    "    \"token_pattern\": r'\\w{1,}',\n",
    "    \"sublinear_tf\": True,\n",
    "    \"dtype\": np.float32,\n",
    "    \"norm\": 'l2',\n",
    "    #\"min_df\":5,\n",
    "    #\"max_df\":.9,\n",
    "    \"smooth_idf\":False\n",
    "}\n",
    "\n",
    "\n",
    "def get_col(col_name): return lambda x: x[col_name]\n",
    "\n",
    "vectorizer = FeatureUnion([\n",
    "        ('description',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=16000,\n",
    "            **tfidf_para,\n",
    "            preprocessor=get_col('description'))),\n",
    "        ('text_feat',CountVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            max_features=5000,\n",
    "            preprocessor=get_col('text_feat'))),\n",
    "        ('title',TfidfVectorizer(\n",
    "            ngram_range=(1, 2),\n",
    "            **tfidf_para,\n",
    "            max_features=5000,\n",
    "            preprocessor=get_col('title')))\n",
    "    ])\n",
    "\n",
    "\n",
    "start_vect=time.time()\n",
    "vectorizer.fit(df.to_dict('records'))\n",
    "\n",
    "ready_df = vectorizer.transform(df.to_dict('records'))\n",
    "print(ready_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization Runtime: 0.05 Minutes\n"
     ]
    }
   ],
   "source": [
    "tfvocab = vectorizer.get_feature_names()\n",
    "print(\"Vectorization Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))\n",
    "\n",
    "df.drop(['item_id','description','title','text_feat'],axis=1,inplace=True)\n",
    "\n",
    "df.drop('user_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>id</th>\n",
       "      <th>dullness</th>\n",
       "      <th>whiteness</th>\n",
       "      <th>average_pixel_width</th>\n",
       "      <th>blurrness</th>\n",
       "      <th>resnet50_score</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Weekd of Year</th>\n",
       "      <th>Day of Month</th>\n",
       "      <th>desc_punctuation_cnt</th>\n",
       "      <th>desc_upper_case_word_cnt</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>description_num_chars</th>\n",
       "      <th>description_num_words</th>\n",
       "      <th>description_num_unique_words</th>\n",
       "      <th>description_words_vs_unique</th>\n",
       "      <th>text_feat_num_chars</th>\n",
       "      <th>text_feat_num_words</th>\n",
       "      <th>text_feat_num_unique_words</th>\n",
       "      <th>text_feat_words_vs_unique</th>\n",
       "      <th>title_num_chars</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_num_unique_words</th>\n",
       "      <th>title_words_vs_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6.214610</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1311</td>\n",
       "      <td>3314</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>632.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>3002</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>453.89</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7.346011</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1246</td>\n",
       "      <td>1797</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.59</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1654.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>478</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>4791</td>\n",
       "      <td>20.49</td>\n",
       "      <td>44.58</td>\n",
       "      <td>4.38</td>\n",
       "      <td>518.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>367</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>91.111111</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>354</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>7.313221</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>8583</td>\n",
       "      <td>1.08</td>\n",
       "      <td>87.29</td>\n",
       "      <td>4.26</td>\n",
       "      <td>383.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  region  city  parent_category_name  category_name       price  \\\n",
       "0           0      15   256                     0             40    6.214610   \n",
       "1           1       3   102                     2              4    9.210340   \n",
       "2           2      10   241                     0             43    7.346011   \n",
       "3           3      22   478                     7             33 -999.000000   \n",
       "4           4      13   354                     4             41    7.313221   \n",
       "\n",
       "   item_seq_number  user_type  image_top_1    id  dullness  whiteness  \\\n",
       "0               21          1         1311  3314     84.56       0.00   \n",
       "1                2          1          667  3002      0.00       0.00   \n",
       "2              129          0         1246  1797      0.00      87.59   \n",
       "3                2          1          228  4791     20.49      44.58   \n",
       "4               12          1         1824  8583      1.08      87.29   \n",
       "\n",
       "   average_pixel_width  blurrness  resnet50_score  Weekday  Weekd of Year  \\\n",
       "0                 4.33     632.23            0.43        1             13   \n",
       "1                 1.48     453.89            0.39        1             12   \n",
       "2                 3.98    1654.58            1.00        5             11   \n",
       "3                 4.38     518.58            0.46        2             11   \n",
       "4                 4.26     383.30            0.47        1             12   \n",
       "\n",
       "   Day of Month  desc_punctuation_cnt  desc_upper_case_word_cnt  \\\n",
       "0            28                     2                         0   \n",
       "1            21                     1                         0   \n",
       "2            18                     2                         0   \n",
       "3            15                    13                         0   \n",
       "4            21                     3                         1   \n",
       "\n",
       "   stopword_count  description_num_chars  description_num_words  \\\n",
       "0               1                     49                      7   \n",
       "1               0                     27                      3   \n",
       "2               6                    128                     23   \n",
       "3               8                    367                     45   \n",
       "4               2                     66                      9   \n",
       "\n",
       "   description_num_unique_words  description_words_vs_unique  \\\n",
       "0                             7                   100.000000   \n",
       "1                             3                   100.000000   \n",
       "2                            22                    95.652174   \n",
       "3                            41                    91.111111   \n",
       "4                             9                   100.000000   \n",
       "\n",
       "   text_feat_num_chars  text_feat_num_words  text_feat_num_unique_words  \\\n",
       "0                   17                    3                           2   \n",
       "1                   48                    7                           7   \n",
       "2                   32                    4                           4   \n",
       "3                   16                    3                           2   \n",
       "4                   30                    5                           4   \n",
       "\n",
       "   text_feat_words_vs_unique  title_num_chars  title_num_words  \\\n",
       "0                  66.666667               29                5   \n",
       "1                 100.000000               38                5   \n",
       "2                 100.000000               10                2   \n",
       "3                  66.666667               17                2   \n",
       "4                  80.000000               18                3   \n",
       "\n",
       "   title_num_unique_words  title_words_vs_unique  \n",
       "0                       5                  100.0  \n",
       "1                       5                  100.0  \n",
       "2                       2                  100.0  \n",
       "3                       2                  100.0  \n",
       "4                       3                  100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows',50, 'display.max_columns', 50):\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>dullness</th>\n",
       "      <th>whiteness</th>\n",
       "      <th>average_pixel_width</th>\n",
       "      <th>blurrness</th>\n",
       "      <th>resnet50_score</th>\n",
       "      <th>desc_punctuation_cnt</th>\n",
       "      <th>desc_upper_case_word_cnt</th>\n",
       "      <th>stopword_count</th>\n",
       "      <th>description_num_words</th>\n",
       "      <th>description_num_unique_words</th>\n",
       "      <th>description_words_vs_unique</th>\n",
       "      <th>text_feat_num_chars</th>\n",
       "      <th>text_feat_num_words</th>\n",
       "      <th>text_feat_num_unique_words</th>\n",
       "      <th>text_feat_words_vs_unique</th>\n",
       "      <th>title_num_words</th>\n",
       "      <th>title_num_unique_words</th>\n",
       "      <th>title_words_vs_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>6.214610</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>1311</td>\n",
       "      <td>84.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.33</td>\n",
       "      <td>632.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>102</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>667</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.48</td>\n",
       "      <td>453.89</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>7.346011</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1246</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.59</td>\n",
       "      <td>3.98</td>\n",
       "      <td>1654.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>22</td>\n",
       "      <td>95.652174</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>478</td>\n",
       "      <td>7</td>\n",
       "      <td>33</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>228</td>\n",
       "      <td>20.49</td>\n",
       "      <td>44.58</td>\n",
       "      <td>4.38</td>\n",
       "      <td>518.58</td>\n",
       "      <td>0.46</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>41</td>\n",
       "      <td>91.111111</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>354</td>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>7.313221</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1824</td>\n",
       "      <td>1.08</td>\n",
       "      <td>87.29</td>\n",
       "      <td>4.26</td>\n",
       "      <td>383.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   region  city  parent_category_name  category_name       price  \\\n",
       "0      15   256                     0             40    6.214610   \n",
       "1       3   102                     2              4    9.210340   \n",
       "2      10   241                     0             43    7.346011   \n",
       "3      22   478                     7             33 -999.000000   \n",
       "4      13   354                     4             41    7.313221   \n",
       "\n",
       "   item_seq_number  user_type  image_top_1  dullness  whiteness  \\\n",
       "0               21          1         1311     84.56       0.00   \n",
       "1                2          1          667      0.00       0.00   \n",
       "2              129          0         1246      0.00      87.59   \n",
       "3                2          1          228     20.49      44.58   \n",
       "4               12          1         1824      1.08      87.29   \n",
       "\n",
       "   average_pixel_width  blurrness  resnet50_score  desc_punctuation_cnt  \\\n",
       "0                 4.33     632.23            0.43                     2   \n",
       "1                 1.48     453.89            0.39                     1   \n",
       "2                 3.98    1654.58            1.00                     2   \n",
       "3                 4.38     518.58            0.46                    13   \n",
       "4                 4.26     383.30            0.47                     3   \n",
       "\n",
       "   desc_upper_case_word_cnt  stopword_count  description_num_words  \\\n",
       "0                         0               1                      7   \n",
       "1                         0               0                      3   \n",
       "2                         0               6                     23   \n",
       "3                         0               8                     45   \n",
       "4                         1               2                      9   \n",
       "\n",
       "   description_num_unique_words  description_words_vs_unique  \\\n",
       "0                             7                   100.000000   \n",
       "1                             3                   100.000000   \n",
       "2                            22                    95.652174   \n",
       "3                            41                    91.111111   \n",
       "4                             9                   100.000000   \n",
       "\n",
       "   text_feat_num_chars  text_feat_num_words  text_feat_num_unique_words  \\\n",
       "0                   17                    3                           2   \n",
       "1                   48                    7                           7   \n",
       "2                   32                    4                           4   \n",
       "3                   16                    3                           2   \n",
       "4                   30                    5                           4   \n",
       "\n",
       "   text_feat_words_vs_unique  title_num_words  title_num_unique_words  \\\n",
       "0                  66.666667                5                       5   \n",
       "1                 100.000000                5                       5   \n",
       "2                 100.000000                2                       2   \n",
       "3                  66.666667                2                       2   \n",
       "4                  80.000000                3                       3   \n",
       "\n",
       "   title_words_vs_unique  \n",
       "0                  100.0  \n",
       "1                  100.0  \n",
       "2                  100.0  \n",
       "3                  100.0  \n",
       "4                  100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 26)\n"
     ]
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0','Weekday','Weekd of Year','Day of Month','description_num_chars','title_num_chars','id'],axis=1,inplace=True)\n",
    "\n",
    "with pd.option_context('display.max_rows',50, 'display.max_columns', 50):\n",
    "    display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modeling Stage\n",
      "10100 Rows and 23022 Cols\n",
      "Feature Names Length:  23022\n"
     ]
    }
   ],
   "source": [
    "print(\"Modeling Stage\")\n",
    "#Combine Dense Features with Sparse Text Bag of Words Features\n",
    "X = hstack([csr_matrix(df.loc[df_index,:].values),ready_df[:df_index.shape[0]]]) # Sparse Matrix\n",
    "\n",
    "#testing = hstack([csr_matrix(df.loc[testdex,:].values),ready_df[traindex.shape[0]:]])\n",
    "\n",
    "tfvocab = df.columns.tolist() + tfvocab\n",
    "\n",
    "for shape in [X]:\n",
    "    print(\"{} Rows and {} Cols\".format(*shape.shape))\n",
    "\n",
    "print(\"Feature Names Length: \",len(tfvocab))\n",
    "#del df\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=100, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler(with_mean=False)\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Light Gradient Boosting Regressor\n"
     ]
    }
   ],
   "source": [
    "print(\"Light Gradient Boosting Regressor\")\n",
    "lgbm_params =  {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'max_depth': 25,\n",
    "    'num_leaves': 37,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 10,\n",
    "    'learning_rate': 0.020,\n",
    "    'num_iterations': 300,\n",
    "    'verbose': 0,\n",
    "    'lambda_l1': 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=400, n_iter=7, random_state=42).fit(X_train_scaled)\n",
    "X_train_reduced = svd.transform(X_train_scaled)\n",
    "X_test_reduced = svd.transform(X_test_scaled)\n",
    "#tfvocab_reduced = svd.transform(tfvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(X_train_reduced, y_train)\n",
    "                #feature_name=tfvocab,\n",
    "                #categorical_feature = categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23604678859289044\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(\n",
    "            lgbm_params,\n",
    "            lgtrain,\n",
    "            num_boost_round=16000,\n",
    "            #valid_sets=[lgtrain, lgvalid],\n",
    "            #valid_names=['train','valid'],\n",
    "            #early_stopping_rounds=200,\n",
    "            #verbose_eval=23022\n",
    "        )\n",
    "lgb_predicted = lgb_clf.predict(X_test_reduced)\n",
    "lgb_rms = sqrt(mean_squared_error(y_test, lgb_predicted))\n",
    "print(lgb_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
